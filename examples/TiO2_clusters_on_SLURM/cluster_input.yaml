inputs:
    energy_files_path: /path_to_LAMMPS_input_files_directory/TiO2_clusters

structure_record:
    cluster:
        max_dia: 7
        box_abc:
            - 18
            - 18
            - 18
        lin_sph_ratio: 0.999
        radius_rand_linear: 1.75
        tol_rand_linear: 0.2
    max_bond_dist: 2.8
    min_dist:
        sp1_sp1: 1.3
        sp1_sp2: 1.3
        sp2_sp2: 1.3

    species:
        species1:
            name: Ti
            min_num: 6
            max_num: 7
            mu: -3.4 # random
        species2:
            name: O
            min_num: 8
            max_num: 11
            mu: -0.81 # random
    stopper:
        num_calcs: 1000

population_limits:
    initial_population: 10
    total_population: 200
    pool: 50

energy_code: lammps
energy_obj_fn: mu_based
energy_exec_cmd: srun --mpi=pmi2 lmp_mpi -in in.min

#exp_sim_1: PDF
#exp_sim_1_params:
#    exp_pdf_file: /path_to_exp_pdf/exp_pdf_data.txt
#    stretch: 1.03
#    Uiso_val: 0.02
#    scale: 2.0
#    delta1: 1.0
#    delta2: 4.0
#    qdamp: 0.01
#    xmin: 1.5
#    xmax: 7.0
#    minimize_method: L-BFGS-B

# pool_capacity: 200

select_params:
    objective_fn_type: single
    adjust_k_every: 5
    num_required_above_50: 20
    num_models_before_pareto: 5 # Not applicable for single obj

mating_constraints:
    num_parents_fraction: 0.1
    attach_type_fraction: 0.3

basinhopping_constraints:
    perturb_box: [[0.4, 0.6], [0.4, 0.6], [0.6, 0.4]]
    jump_fraction: 0.12

evolve_probabilities:
    1: 0.3
    2: 0
    3: 0.5
    4: 0.2

workers: # contains specifications for each dask worker job
    cluster: "SLURM" # Specify type of scheduler
    max_workers: 2 # Number of parallel calculations of models
    num_cores: 1 # cpus-per-task option
    total_mem: "2GB" # total memory for the job (--mem option)
    project_name: "my_project" # project under which job to be requested
    submit_queue: "general_compute" # queue in which to submit job
    node_type: "ib0" # infiniband or haswell etc
    walltime: "1:00:00" # estimated entire walltime a worker job shall run
    job_extra: # any other PBS/SLURM submit options
        - "--ntasks=2"  # SBATCH options directly provided
        - "--nodes=1"
